{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11fb8447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.stats\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e735dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_memory(word_list):\n",
    "    mem = []\n",
    "    for i in word_list:\n",
    "        mem.append(word_matrix[word_dic[i]])\n",
    "    return np.array(mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b0a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_matrix(mat):\n",
    "    mag = np.sum(mat**2, axis=1)\n",
    "    mag[mag == 0] = 1\n",
    "    mag = np.sqrt(mag)\n",
    "    return np.transpose(np.transpose(mat) / mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abce356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def echo_intensity(probes, mem, tau=3):\n",
    "    normed_mem = normalize_matrix(mem)\n",
    "    return np.sum((probes @ np.transpose(normed_mem))**3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "185336d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_sq(x, y):\n",
    "    cor = scipy.stats.pearsonr(x, y)\n",
    "    return cor[0]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35dddc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(x, y):\n",
    "    return np.sum((x - y)**2) / len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "579da74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f67f8f",
   "metadata": {},
   "source": [
    "The LSA semantic space can be downloaded from https://osf.io/s6db4. The file was too big to share on Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f512a954",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LSA semantic space', 'rb') as f:\n",
    "    word_dic, word_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dab85888",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_matrix = normalize_matrix(word_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3a7f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c9a04d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stims_from_csv(filename):\n",
    "    df = []\n",
    "    with open(filename, 'r') as f:\n",
    "        csvreader = csv.reader(f)\n",
    "        for i in csvreader:\n",
    "            df.append(i)\n",
    "    df = df[1:]\n",
    "    r_old = [i[1].lower() for i in df if i[2]=='R' and i[3]=='old']\n",
    "    f_old = [i[1].lower() for i in df if i[2]=='F' and i[3]=='old']\n",
    "    r_new = [i[1].lower() for i in df if i[2]=='R' and i[3]=='new']\n",
    "    f_new = [i[1].lower() for i in df if i[2]=='F' and i[3]=='new']\n",
    "    new_new = [i[1].lower() for i in df if i[2]=='New' and i[3]=='new']\n",
    "    return r_old + f_old + r_new + f_new + new_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34948db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stims_a = get_stims_from_csv('df_testlist1.csv')\n",
    "stims_b = get_stims_from_csv('df_testlist2.csv')\n",
    "stims_c = get_stims_from_csv('df_testlist3.csv')\n",
    "stims_d = get_stims_from_csv('df_testlist4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dee09d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empirical means\n",
    "emp_250_250 = [0.58402778, 0.53263889, 0.39722222, 0.33055556, 0.3125]\n",
    "emp_250_2 = [0.67616959, 0.47660819, 0.29093567, 0.23830409, 0.20248538]\n",
    "emp_2_250 = [0.69642857, 0.51455026, 0.24074074, 0.20767196, 0.13425926]\n",
    "emp_2_2 = [0.71544715, 0.53319783, 0.2601626 , 0.18834688, 0.14295393]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a41b511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all empirical means in one array (for computing R-squared and MSE)\n",
    "emp_all = [0.58402778, 0.53263889, 0.39722222, 0.33055556, 0.3125, 0.67616959, 0.47660819, 0.29093567, 0.23830409, 0.20248538, 0.69642857, 0.51455026, 0.24074074, 0.20767196, 0.13425926, 0.71544715, 0.53319783, 0.2601626 , 0.18834688, 0.14295393]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a9004ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fc1687c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Selective Rehearsal Simulation MEANS\n",
      "\n",
      "condition    R old      F old      R rel      F rel      Unrel\n",
      "\n",
      "short/short [0.60227778 0.50697222 0.43044444 0.394      0.28408333]\n",
      "short/long  [0.6235     0.45475    0.35583333 0.30716667 0.20136111]\n",
      "long/short  [0.62533333 0.56405556 0.25027778 0.23694444 0.12255556]\n",
      "long/long   [0.68580556 0.56458333 0.26077778 0.22372222 0.11847222]\n"
     ]
    }
   ],
   "source": [
    "#Selective Rehearsal\n",
    "\n",
    "L = .02  # Learning rate\n",
    "l_decay = .9 # pre-cue decay rate\n",
    "R = .01 # post-cue boost rate\n",
    "cue_decay = .5 # post-cue decay rate\n",
    "\n",
    "t = 3 # retrieval gradient\n",
    "\n",
    "cond = [(1, 1, 45, 'short/short'), (1, 8, 40, 'short/long '), (8, 1, 39, 'long/short '), (8, 8, 40, 'long/long  ')]\n",
    "\n",
    "overall_means = []\n",
    "sds = []\n",
    "print('            Selective Rehearsal Simulation MEANS\\n')\n",
    "print('condition    R old      F old      R rel      F rel      Unrel\\n')\n",
    "for c in cond:\n",
    "    sim_list = []\n",
    "    for s in range(0, 1000):\n",
    "        if s < 250:\n",
    "            probes = make_memory(stims_a)\n",
    "        elif s < 500:\n",
    "            probes = make_memory(stims_b)\n",
    "        elif s < 750:\n",
    "            probes = make_memory(stims_c)\n",
    "        else:\n",
    "            probes = make_memory(stims_d)\n",
    "        mem = probes[:72].copy()\n",
    "        r_mem = np.zeros((36, 300))\n",
    "        f_mem = np.zeros((36, 300))\n",
    "        l = L + 0\n",
    "        for i in range(0, c[0]):\n",
    "            r_encode = np.random.choice([0, 1], size=(36, 300), replace=True, p=[1-l, l])\n",
    "            f_encode = np.random.choice([0, 1], size=(36, 300), replace=True, p=[1-l, l])\n",
    "            r_mem[r_encode == 1] = 1\n",
    "            f_mem[f_encode == 1] = 1\n",
    "            l *= l_decay\n",
    "        r = l + R\n",
    "        for i in range(0, c[1]):\n",
    "            r_encode = np.random.choice([0, 1], size=(36, 300), replace=True, p=[1-r, r])\n",
    "            f_encode = np.random.choice([0, 1], size=(36, 300), replace=True, p=[1-l, l])\n",
    "            r_mem[r_encode == 1] = 1\n",
    "            f_mem[f_encode == 1] = 1\n",
    "            l *= cue_decay\n",
    "            r *= cue_decay\n",
    "        mem[:36] *= r_mem\n",
    "        mem[36:] *= f_mem\n",
    "        fams = echo_intensity(probes, mem, tau=t)\n",
    "        criterion = np.percentile(fams, 100-c[2])\n",
    "        r_hits = np.sum(fams[:36] > criterion) / 36\n",
    "        f_hits = np.sum(fams[36:72] > criterion) / 36\n",
    "        r_fa = np.sum(fams[72:90] > criterion) / 18\n",
    "        f_fa = np.sum(fams[90:108] > criterion) / 18\n",
    "        u_fa = np.sum(fams[108:144] > criterion) / 36\n",
    "        sim_list.append([r_hits, f_hits, r_fa, f_fa, u_fa])\n",
    "    sim_means = np.mean(sim_list, axis=0)\n",
    "    sds.append(np.std(sim_list, axis=0, ddof=1))\n",
    "    print(c[3], sim_means)\n",
    "    overall_means.append(sim_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6724e993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Selective Rehearsal Simulation Standard Deviations\n",
      "\n",
      "condition    R old      F old      R rel      F rel      Unrel\n",
      "\n",
      "short/short [0.08250373 0.07231178 0.12142764 0.12247948 0.08686609]\n",
      "short/long  [0.08228911 0.07481775 0.11145779 0.10328875 0.07094774]\n",
      "long/short  [0.07330819 0.07228168 0.08682353 0.07928718 0.0447977 ]\n",
      "long/long   [0.06972488 0.07168623 0.08654534 0.07833647 0.04350774]\n"
     ]
    }
   ],
   "source": [
    "# print SDS\n",
    "print('            Selective Rehearsal Simulation Standard Deviations\\n')\n",
    "print('condition    R old      F old      R rel      F rel      Unrel\\n')\n",
    "for i in range(0, 4):\n",
    "    print(cond[i][3], sds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25543714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selective Rehearsal fits\n",
      "\n",
      "R-squared:  0.9584387378073439\n",
      "Mean Squared Error:  0.0015720045014903515\n"
     ]
    }
   ],
   "source": [
    "sim_all = []\n",
    "for x in overall_means:\n",
    "    sim_all.extend(x)\n",
    "print('Selective Rehearsal fits\\n')\n",
    "print('R-squared: ', r_sq(np.array(sim_all), emp_all))\n",
    "print('Mean Squared Error: ', mse(np.array(sim_all), emp_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1387d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Attention Inhibition Simulation MEANS\n",
      "\n",
      "condition    R old      F old      R rel      F rel      Unrel\n",
      "\n",
      "short/short [0.58772222 0.50011111 0.43711111 0.39916667 0.29958333]\n",
      "short/long  [0.52869444 0.44741667 0.39211111 0.36055556 0.25866667]\n",
      "long/short  [0.71580556 0.50280556 0.25433333 0.20066667 0.10944444]\n",
      "long/long   [0.73591667 0.52425    0.26461111 0.21022222 0.11352778]\n"
     ]
    }
   ],
   "source": [
    "#active forgetting\n",
    "\n",
    "L = .04 # learning rate\n",
    "l_decay = .8 # learning rate decay\n",
    "F = .2 # forgetting rate\n",
    "f_decay = 0 # forgetting rate decay\n",
    "\n",
    "t = 3 # retrieval gradient\n",
    "\n",
    "cond = [(1, 1, 45, 'short/short'), (1, 8, 40, 'short/long '), (8, 1, 39, 'long/short '), (8, 8, 40, 'long/long  ')]\n",
    "\n",
    "overall_means = []\n",
    "sds = []\n",
    "print('            Attention Inhibition Simulation MEANS\\n')\n",
    "print('condition    R old      F old      R rel      F rel      Unrel\\n')\n",
    "for c in cond:\n",
    "    sim_list = []\n",
    "    for s in range(0, 1000):\n",
    "        if s < 250:\n",
    "            probes = make_memory(stims_a)\n",
    "        elif s < 500:\n",
    "            probes = make_memory(stims_b)\n",
    "        elif s < 750:\n",
    "            probes = make_memory(stims_c)\n",
    "        else:\n",
    "            probes = make_memory(stims_d)\n",
    "        mem = probes[:72].copy()\n",
    "        r_mem = np.zeros((36, 300))\n",
    "        f_mem = np.zeros((36, 300))\n",
    "        l = L + 0\n",
    "        f = F + 0\n",
    "        for i in range(0, c[0]):\n",
    "            r_encode = np.random.choice([0, 1], size=(36, 300), replace=True, p=[1-l, l])\n",
    "            f_encode = np.random.choice([0, 1], size=(36, 300), replace=True, p=[1-l, l])\n",
    "            r_mem[r_encode == 1] = 1\n",
    "            f_mem[f_encode == 1] = 1\n",
    "            l *= l_decay\n",
    "        for i in range(0, c[1]):\n",
    "            f_forget = np.random.choice([0, 1], size=(36, 300), replace=True, p=[1-f, f])\n",
    "            f_mem[f_forget == 1] = 0\n",
    "            f *= f_decay\n",
    "        mem[:36] *= r_mem\n",
    "        mem[36:] *= f_mem\n",
    "        fams = echo_intensity(probes, mem, tau=t)\n",
    "        criterion = np.percentile(fams, 100-c[2])\n",
    "        r_hits = np.sum(fams[:36] > criterion) / 36\n",
    "        f_hits = np.sum(fams[36:72] > criterion) / 36\n",
    "        r_fa = np.sum(fams[72:90] > criterion) / 18\n",
    "        f_fa = np.sum(fams[90:108] > criterion) / 18\n",
    "        u_fa = np.sum(fams[108:144] > criterion) / 36\n",
    "        sim_list.append([r_hits, f_hits, r_fa, f_fa, u_fa])\n",
    "    sim_means = np.mean(sim_list, axis=0)\n",
    "    sds.append(np.std(sim_list, axis=0, ddof=1))\n",
    "    print(c[3], sim_means)\n",
    "    overall_means.append(sim_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "947dc3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Attention Inhibition Simulation Standard Deviations\n",
      "\n",
      "condition    R old      F old      R rel      F rel      Unrel\n",
      "\n",
      "short/short [0.07969496 0.07470734 0.12993405 0.12675899 0.08578933]\n",
      "short/long  [0.08402059 0.07289451 0.12175972 0.12547442 0.08157061]\n",
      "long/short  [0.06905345 0.0708813  0.09010533 0.07177479 0.0435399 ]\n",
      "long/long   [0.06491574 0.06512315 0.08905194 0.07418544 0.04203284]\n"
     ]
    }
   ],
   "source": [
    "# print SDS\n",
    "print('            Attention Inhibition Simulation Standard Deviations\\n')\n",
    "print('condition    R old      F old      R rel      F rel      Unrel\\n')\n",
    "for i in range(0, 4):\n",
    "    print(cond[i][3], sds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8df70181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention inhibition fits\n",
      "\n",
      "R-squared:  0.9141010886181157\n",
      "Mean Squared Error:  0.0030851370479070194\n"
     ]
    }
   ],
   "source": [
    "sim_all = []\n",
    "for x in overall_means:\n",
    "    sim_all.extend(x)\n",
    "print('Attention inhibition fits\\n')\n",
    "print('R-squared: ', r_sq(np.array(sim_all), emp_all))\n",
    "print('Mean Squared Error: ', mse(np.array(sim_all), emp_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb60de69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Unbinding Simulation MEANS\n",
      "\n",
      "condition    R old      F old      R rel      F rel      Unrel\n",
      "\n",
      "short/short [0.58319444 0.52094444 0.43105556 0.40377778 0.284     ]\n",
      "short/long  [0.72994444 0.53275    0.28111111 0.19855556 0.10858333]\n",
      "long/short  [0.69130556 0.52580556 0.26511111 0.19688889 0.10744444]\n",
      "long/long   [0.79163889 0.55208333 0.24688889 0.14566667 0.07111111]\n"
     ]
    }
   ],
   "source": [
    "# Context Unbinding\n",
    "l = .02 # learning rate\n",
    "f = .8 # unbinding rate\n",
    "\n",
    "context_size = 50 # context vector size\n",
    "t = 3 # retrieval gradient\n",
    "\n",
    "cond = [(1, 1, 45, 'short/short'), (1, 8, 40, 'short/long '), (8, 1, 39, 'long/short '), (8, 8, 40, 'long/long  ')]\n",
    "\n",
    "overall_means = []\n",
    "sds = []\n",
    "print('            Unbinding Simulation MEANS\\n')\n",
    "print('condition    R old      F old      R rel      F rel      Unrel\\n')\n",
    "for c in cond:\n",
    "    sim_list = []\n",
    "    for s in range(0, 1000):\n",
    "        if s < 250:\n",
    "            stims = make_memory(stims_a)\n",
    "        elif s < 500:\n",
    "            stims = make_memory(stims_b)\n",
    "        elif s < 750:\n",
    "            stims = make_memory(stims_c)\n",
    "        else:\n",
    "            stims = make_memory(stims_d)\n",
    "        context_matrix = np.ones((144, context_size)) * np.random.normal(0, 1/np.sqrt(300), context_size)\n",
    "        probes = np.concatenate((stims, context_matrix), axis=1)\n",
    "        mem = probes[:72].copy()\n",
    "        r_mem = np.zeros((36, 300+context_size))\n",
    "        f_mem = np.zeros((36, 300+context_size))\n",
    "        for i in range(0, c[0]):\n",
    "            r_encode = np.random.choice([0, 1], size=(36, 300+context_size), replace=True, p=[1-l, l])\n",
    "            f_encode = np.random.choice([0, 1], size=(36, 300+context_size), replace=True, p=[1-l, l])\n",
    "            r_mem[r_encode == 1] = 1\n",
    "            f_mem[f_encode == 1] = 1\n",
    "        for i in range(0, c[1]):\n",
    "            r_encode = np.random.choice([0, 1], size=(36, 300+context_size), replace=True, p=[1-l, l])\n",
    "            f_encode = np.concatenate((np.random.choice([0, 1], size=(36, 300), replace=True, p=[1-l, l]), np.zeros((36, context_size))), axis=1)\n",
    "            f_forget = np.concatenate((np.zeros((36, 300)), np.random.choice([0, 1], size=(36, context_size), replace=True, p=[1-f, f])), axis=1)\n",
    "            r_mem[r_encode == 1] = 1\n",
    "            f_mem[f_encode == 1] = 1\n",
    "            f_mem[f_forget == 1] = 0\n",
    "        mem[:36] *= r_mem\n",
    "        mem[36:] *= f_mem\n",
    "        fams = echo_intensity(probes, mem, tau=t)\n",
    "        criterion = np.percentile(fams, 100-c[2])\n",
    "        r_hits = np.sum(fams[:36] > criterion) / 36\n",
    "        f_hits = np.sum(fams[36:72] > criterion) / 36\n",
    "        r_fa = np.sum(fams[72:90] > criterion) / 18\n",
    "        f_fa = np.sum(fams[90:108] > criterion) / 18\n",
    "        u_fa = np.sum(fams[108:144] > criterion) / 36\n",
    "        sim_list.append([r_hits, f_hits, r_fa, f_fa, u_fa])\n",
    "    sim_means = np.mean(sim_list, axis=0)\n",
    "    sds.append(np.std(sim_list, axis=0, ddof=1))\n",
    "    print(c[3], sim_means)\n",
    "    overall_means.append(sim_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5fdb2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Unbinding Simulation Standard Deviations\n",
      "\n",
      "condition    R old      F old      R rel      F rel      Unrel\n",
      "\n",
      "short/short [0.0816573  0.07965835 0.12429958 0.12523136 0.08503447]\n",
      "short/long  [0.06303699 0.07144655 0.09799709 0.07188378 0.04600945]\n",
      "long/short  [0.06529702 0.07197969 0.09217483 0.06964716 0.04240919]\n",
      "long/long   [0.05431833 0.06573995 0.11165012 0.06864299 0.03899163]\n"
     ]
    }
   ],
   "source": [
    "# print SDS\n",
    "print('            Unbinding Simulation Standard Deviations\\n')\n",
    "print('condition    R old      F old      R rel      F rel      Unrel\\n')\n",
    "for i in range(0, 4):\n",
    "    print(cond[i][3], sds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7540845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context unbinding fits\n",
      "\n",
      "R-squared:  0.9743964013229056\n",
      "Mean Squared Error:  0.001944838462277374\n"
     ]
    }
   ],
   "source": [
    "# compute model fits\n",
    "sim_all = []\n",
    "for x in overall_means:\n",
    "    sim_all.extend(x)\n",
    "print('Context unbinding fits\\n')\n",
    "print('R-squared: ', r_sq(np.array(sim_all), emp_all))\n",
    "print('Mean Squared Error: ', mse(np.array(sim_all), emp_all))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
